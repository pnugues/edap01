{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "retired-darkness",
   "metadata": {},
   "source": [
    "# Classification with logistic regression and scikit_learn\n",
    "\n",
    "__Individual assignment__\n",
    "\n",
    "Author of the assignment: Pierre Nugues\n",
    "\n",
    "__Student name__:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-bedroom",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Imports you may use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "complete-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-belgium",
   "metadata": {},
   "source": [
    "### The dataset\n",
    "You will use the arrays below:\n",
    "1. `X` contains the counts of letters and of _A_ s as well as a column of ones for the intercept;\n",
    "2. `y` contains the classes, where 0 is for English and 1 for French."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acceptable-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1.0, 35680.0, 2217.0],\n",
    "              [1.0, 42514.0, 2761.0],\n",
    "              [1.0, 15162.0, 990.0],\n",
    "              [1.0, 35298.0, 2274.0],\n",
    "              [1.0, 29800.0, 1865.0],\n",
    "              [1.0, 40255.0, 2606.0],\n",
    "              [1.0, 74532.0, 4805.0],\n",
    "              [1.0, 37464.0, 2396.0],\n",
    "              [1.0, 31030.0, 1993.0],\n",
    "              [1.0, 24843.0, 1627.0],\n",
    "              [1.0, 36172.0, 2375.0],\n",
    "              [1.0, 39552.0, 2560.0],\n",
    "              [1.0, 72545.0, 4597.0],\n",
    "              [1.0, 75352.0, 4871.0],\n",
    "              [1.0, 18031.0, 1119.0],\n",
    "              [1.0, 36961.0, 2503.0],\n",
    "              [1.0, 43621.0, 2992.0],\n",
    "              [1.0, 15694.0, 1042.0],\n",
    "              [1.0, 36231.0, 2487.0],\n",
    "              [1.0, 29945.0, 2014.0],\n",
    "              [1.0, 40588.0, 2805.0],\n",
    "              [1.0, 75255.0, 5062.0],\n",
    "              [1.0, 37709.0, 2643.0],\n",
    "              [1.0, 30899.0, 2126.0],\n",
    "              [1.0, 25486.0, 1784.0],\n",
    "              [1.0, 37497.0, 2641.0],\n",
    "              [1.0, 40398.0, 2766.0],\n",
    "              [1.0, 74105.0, 5047.0],\n",
    "              [1.0, 76725.0, 5312.0],\n",
    "              [1.0, 18317.0, 1215.0]])\n",
    "y = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-chair",
   "metadata": {},
   "source": [
    "### Normalize the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-engagement",
   "metadata": {},
   "source": [
    "Gradient descent algorithms can be very sensitive to the range. Therefore, we normalize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abroad-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(Xy):\n",
    "    maxima = np.amax(Xy, axis=0)\n",
    "    Xy = 1/maxima * Xy\n",
    "    return (Xy, maxima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intellectual-arcade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.46503747, 0.41735693],\n",
       "       [1.        , 0.55410883, 0.51976657],\n",
       "       [1.        , 0.19761486, 0.18637048],\n",
       "       [1.        , 0.46005865, 0.42808735],\n",
       "       [1.        , 0.38840013, 0.35109187],\n",
       "       [1.        , 0.52466601, 0.49058735],\n",
       "       [1.        , 0.9714174 , 0.90455572],\n",
       "       [1.        , 0.48828935, 0.45105422],\n",
       "       [1.        , 0.40443141, 0.37518825],\n",
       "       [1.        , 0.32379277, 0.30628765],\n",
       "       [1.        , 0.47144998, 0.4471009 ],\n",
       "       [1.        , 0.51550342, 0.48192771],\n",
       "       [1.        , 0.94551971, 0.8653991 ],\n",
       "       [1.        , 0.98210492, 0.91698042],\n",
       "       [1.        , 0.23500815, 0.21065512],\n",
       "       [1.        , 0.48173346, 0.47119729],\n",
       "       [1.        , 0.56853698, 0.56325301],\n",
       "       [1.        , 0.20454871, 0.19615964],\n",
       "       [1.        , 0.47221896, 0.46818524],\n",
       "       [1.        , 0.39029   , 0.37914157],\n",
       "       [1.        , 0.52900619, 0.5280497 ],\n",
       "       [1.        , 0.98084066, 0.95293675],\n",
       "       [1.        , 0.49148257, 0.49755271],\n",
       "       [1.        , 0.40272401, 0.4002259 ],\n",
       "       [1.        , 0.33217335, 0.33584337],\n",
       "       [1.        , 0.48871945, 0.4971762 ],\n",
       "       [1.        , 0.52652981, 0.52070783],\n",
       "       [1.        , 0.96585207, 0.95011295],\n",
       "       [1.        , 1.        , 1.        ],\n",
       "       [1.        , 0.23873574, 0.22872741]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm, maxima = normalize(X)\n",
    "X_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-corruption",
   "metadata": {},
   "source": [
    "sklearn handles the intercept so we do not need the first column of ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "juvenile-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:, 1:]\n",
    "X_norm = X_norm[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-running",
   "metadata": {},
   "source": [
    "### sklearn\n",
    "Using the dataset of English and French datapoints, we apply logistic regression with the sklearn API. We need the `LogisticRegression` class, the `fit()` and `predict()` functions. The weights are in the `coef_` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "incomplete-sandwich",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03210407,  0.48483739]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model = model.fit(X, y)\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-press",
   "metadata": {},
   "source": [
    "We predict the classes of the ${X}$ with the `predict()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "partial-ratio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-moisture",
   "metadata": {},
   "source": [
    "We predict the class probabilities of the ${X}$ with the `predict_proba()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "equal-mistake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 4.70168695e-30],\n",
       "       [1.00000000e+00, 8.59479008e-11],\n",
       "       [9.76197588e-01, 2.38024122e-02],\n",
       "       [1.00000000e+00, 1.00087464e-12],\n",
       "       [1.00000000e+00, 3.44315694e-22],\n",
       "       [1.00000000e+00, 6.21540855e-12],\n",
       "       [1.00000000e+00, 8.10231988e-27],\n",
       "       [1.00000000e+00, 3.08500676e-17],\n",
       "       [1.00000000e+00, 2.18523269e-12],\n",
       "       [9.96570570e-01, 3.42943036e-03],\n",
       "       [9.98795547e-01, 1.20445330e-03],\n",
       "       [1.00000000e+00, 8.11464193e-12],\n",
       "       [1.00000000e+00, 6.54115891e-43],\n",
       "       [1.00000000e+00, 2.35921417e-24],\n",
       "       [1.00000000e+00, 3.53373575e-15],\n",
       "       [9.28146449e-14, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [1.19110878e-02, 9.88088912e-01],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [1.29108435e-08, 9.99999987e-01],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [1.65251967e-02, 9.83474803e-01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
